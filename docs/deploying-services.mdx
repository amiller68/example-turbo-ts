---
title: "Deploying Services"
description: "Setting up infrastructure and deploying new services to AWS"
---

# Deploying Services

This guide covers the steps needed to deploy a new service to your AWS account.

## Prerequisites

NOTE: assume everything described here is setup in `us-east-1`.

### 1. AWS Credentials

You need AWS admin credentials to deploy services:

```bash
export AWS_ACCESS_KEY_ID="your-access-key"
export AWS_SECRET_ACCESS_KEY="your-secret-key"
export AWS_REGION="us-east-1"  # or your preferred region
```

Get these from your AWS IAM Console under Security Credentials.

Your user should have admin access to AWS in order to deploy services without any hiccups.

You will need these credentials exposed in your environment when running:
- `./bin/ecs` commands
- `./bin/docker` commands
- and `terraform` commands

### 2. Route 53 Setup

You'll need a hosted zone for your domain in Route 53.

This will involve:
- creating a hosted zone for your domain in the Route 53 console. This should be a subdomain
  of a domain that you own and can configure DNS for. For example, I own `krondor.org` and have
  created a hosted zone for `aws.krondor.org`.
- adding NS records in your main domain pointing to the subdomain's nameservers
- updating `iac/modules/aws/main.tf` with your domain name. this *should* ideally be configurable
  via an environment variable, but that's not yet implemented. you'll have to replace the hardcoded
  `aws.krondor.org` in the `iac/modules/aws/main.tf` file with your own domain you will use for
  deploying services.

### 3. Terraform State Storage

You'll need to setup a small amount of infrastructure to store your terraform state.

This repository expects the following resources to exist:

- An S3 bucket for storing terraform state called `example-turbo-ts-tf-state`
- A DynamoDB table for state locking called `example-turbo-ts-tf-state-lock`. This will need an index
  on the `LockID` field.

If you'd like to use a different bucket and table name, you may, but you will have to update
`./iac/envs/production/terraform.tf` to configure your provider to use the new bucket and table.

## Deploying ECR Repository

Each service requires a new ECR repository in order to store its images.

If you haven't already, you'll need to create a new ECR repository for your service.

In order to do this, you'll need to add your service to the `iac/envs/ecr/main.tf` file.

```terraform
locals {
  # Add your service to the list by its canonical name
  services = ["example", "your-service-name"]
}
```

And run the following commands to create the repository from `./iac/envs/ecr`:

```bash
# Initialize ECR terraform if needed
terraform init

# see the plan for what will be created
terraform plan

# apply the changes
terraform apply -auto-approve
```

A new ECR repository will be created in your AWS account + region.

Once this is done, CI/CD will be able to push images to the repository.
If you'd like to push images manually during development, you can do so with the `./bin/docker` script. See [docker-build-push.mdx](./docker-build-push.mdx) for more details.

## Deploying ECS Infrastructure

The `iac/modules/aws` module describes an opinionated framework for deploying services to AWS
 managed by ECS and Fargate. In order to deploy a new service, you just need to setup a new
 task definition that references your services image from its respective ECR repository.

All you have to do is define a new module in `iac/modules/aws/services` that describes your
 services requirements, which you can do in as little as ~10 lines of terraform code.
 
The current example service is setup to be a good starting point for new services.

### Defining your service

1. Copy the example service module:

```bash
cp -r iac/modules/aws/services/example iac/modules/aws/services/your-service-name
```

2. Register your service in `iac/modules/aws/services/main.tf`:

```terraform
module "your_service" {
  source           = "./your-service-name"
  # TODO (service-deploy): add your service's specific variables here
}

locals {
  service_modules = {
    "example" = module.example.service,
    # TODO (service-deploy): add your service's module here
    "your-service-name" = module.your_service.service
  }
}
```

If your service requires any additional resources or configurations, you can
 extend the `example` service module to meet your needs. See below for more details on
 the different configuration options.


### Deploying your service

Once you've defined your service, you can deploy it using the following commands from 
 whatever environment you're deploying to. For instance, from the `iac/envs/production` directory:

```bash
# Initialize terraform
terraform init

# see the plan for what will be created
terraform plan

# apply the changes
terraform apply -auto-approve
```

Will create all of the necessary resources for your service. This will include:

- A VPC + related resources (subnets, route tables, etc.)
- An ALB + related resources (security groups, listeners, etc.)
- An ACM certificate for terminating TLS on the ALB
- An ECS cluster
- An ECS task definition + service + task role + execution role

### Accessing your service

After your service is deployed, you can access it at:
`https://{environment}.aws.krondor.org/your-service-name`

(or whatever domain you've configured in Route 53)

## Service Configuration Options

When implementing your service module, you have several configuration options available at different levels.

### Global Defaults

In `iac/modules/aws/services/_defaults/`, define default configurations that are shared across all services:

```terraform
# in iac/modules/aws/services/_defaults/main.tf
# container defaults for all services
output "container" {
  description = "Default container configuration"
  value = {
    # all containers run on port 3000
    port   = 3000
    # have a default of 256 cpu and 512 memory
    cpu    = 256
    memory = 512
    # and reflect our very strict tag + naming conventions
    repository   = var.name
    tag          = var.environment == "production" ? "latest" : "staging-latest"
    # we have a standard health check endpoint for all services
    health_check = "/${var.name}/_status/readyz"
    # and a standard set of environment variables.
    environment = [
      {
        name  = "ENV"
        value = var.environment
      },
      {
        name  = "BASE_PATH"
        value = "/${var.name}"
      }
    ]
  }
}

# service defaults for all services
output "service" {
  description = "Default service configuration"
  value = {
    # a standard description for all services
    description           = "${var.name} service"
    # a standard desired count for all services
    desired_count         = 1
    # a standard auto scaling configuration for all services
    auto_scaling          = true
    min_capacity          = 1
    max_capacity          = 3
    scaling_cpu_threshold = 70
    # a standard listener rule for all services
    #  it is very important that this aligns with the BASE_PATH in the container
    #  environment variables!
    lb_listener_rule = {
      path_pattern = ["/${var.name}/*"]
    }
  }
}
```

### Service Definition Defaults

In your service module's `main.tf`, define default configurations that are specific to your service.
Below is an example of a service definition that:
- ups container resources
- configures new environment variables
- mounts an EFS volume for caching
- defines a policy for accessing other AWS resources

```terraform
locals {
  service = {
    # Container configuration. This must at least be an empty object if
    #  you want to use all of the defaults from the global defaults.
    # However, in the case of the image renderer:
    container = {
      cpu    = 512 # we upped this from 256 to 512 for the image renderer
      memory = 1024 # we upped this from 512 to 1024 for the image renderer
      environment = [
        {
          name  = "AWS_REGION"
          value = var.aws_region
        }
        {
          name  = "AWS_S3_BUCKET"
          value = var.some_bucket.arn
        }
      ]
      # We cache fonts in an EFS volume for the image renderer. This defines where we mount it.
      mount_points = [
        {
          sourceVolume  = "your-cache-volume"
          containerPath = "/app/cache"
          readOnly      = false
        }
      ]
    }

    # And this defines the EFS volume itself.
    volumes = [
      {
        name = "your-cache-volume"
        efs = {
          creation_token   = "your-cache-volume"
          encrypted        = true
          performance_mode = "generalPurpose"
          throughput_mode  = "bursting"
          owner_uid        = "1001"
          owner_gid        = "1001"
          permissions      = "777"
          root_directory   = "/"
        }
      }
    ]

    # Basic services don't need any special permissions. However, if you need
    #  to access other AWS resources, you can define a policy here.
    # If you don't need any special permissions, you can omit this.
    policy = {
      Version = "2012-10-17"
      Statement = [
        {
          Effect = "Allow"
          Action = [
            "s3:GetObject",
            "s3:PutObject"
          ]
          Resource = [
            var.some_bucket.arn,
            "${var.some_bucket.arn}/*"
          ]
        }
      ]
    }
  }
}
```

### Environment-Specific Overrides

Finally, in your environment configuration, you can override the defaults for your service. This is most useful for passing in environment variables for your service.

```terraform
# in iac/envs/{environment}/main.tf
service_configurations = {
  "your-service-name" = {
    # Override container settings
    container = {
      cpu    = 1024  # override the service level default cpu
      memory = 2048  # override the service level default memory
      # append any additional environment variables here
      environment = [
        {
          name  = "MY_STAGE_SPECIFIC_ENV_VAR"
          value = "some-value"
        }
      ]
    }
  }
}
```

### Configuration Hierarchy

Configurations are applied in the following order (later ones override earlier ones):

1. **Global Defaults** (`_defaults/`)
2. **Service Defaults** (your service's `main.tf`)
3. **Environment Overrides** (`envs/{environment}/main.tf`)

## Next Steps

Once your service is deployed, you can interact with it using the `./bin/ecs` script.

See [ecs-commands.mdx](./ecs-commands.mdx) for more details.
